{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import json\n",
    "\n",
    "reddit_post_mapping = {\n",
    "    'CharacterAI': ['CharacterAI', 'CharacterAi_NSFW'],\n",
    "    'HuggingChat': ['HuggingChat'],\n",
    "    'OpenAI': ['GPTStore', 'GPTStoreFR', 'ChatGPTStore'],\n",
    "    'Poe': ['Poe_AI', 'PoeAI_NSFW'],\n",
    "}\n",
    "\n",
    "with open('.reddit.json') as f:\n",
    "    config = json.load(f)\n",
    "    reddit = praw.Reddit(**config)\n",
    "    for forum in reddit_post_mapping:\n",
    "        df = pd.DataFrame()\n",
    "        for subreddit in reddit_post_mapping[forum]:\n",
    "            posts = []\n",
    "            for submission in reddit.subreddit(subreddit).hot(limit=None):\n",
    "                posts.append({\n",
    "                    'Title': submission.title,\n",
    "                    'Question': submission.selftext,\n",
    "                    'subreddit': submission.subreddit.display_name,\n",
    "                    'Link': \"https://www.reddit.com\" + submission.permalink,\n",
    "                    'Creation Time': submission.created,\n",
    "                    'Reply Count': submission.num_comments,\n",
    "                    'Upvote Ratio': submission.upvote_ratio\n",
    "                })\n",
    "            df = pd.concat([df, pd.DataFrame(posts)], ignore_index=True)\n",
    "        df.to_json(f'{forum}_reddit.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "tag_store_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "url = 'https://community.openai.com/tags'\n",
    "driver.get(url)\n",
    "\n",
    "for tag in driver.find_elements(By.XPATH, '//div[@class=\"tag-box\"]/a'):\n",
    "    tag_name = tag.get_attribute('data-tag-name')\n",
    "    if 'store' in tag_name.lower():\n",
    "        tag_store_links.append(tag.get_attribute('href'))\n",
    "        \n",
    "post_store_links = set()\n",
    "\n",
    "for tag_link in tag_store_links:\n",
    "    driver.get(tag_link)\n",
    "    for post in driver.find_elements(By.XPATH, '//tbody[@class=\"topic-list-body\"]/tr'):\n",
    "        post_link = post.find_element(By.XPATH, './/a[@role=\"heading\"]').get_attribute('href')\n",
    "        post_store_links.add(post_link)\n",
    "        \n",
    "posts = pd.DataFrame()\n",
    "for post_link in post_store_links:\n",
    "    json_data = requests.get(post_link + '.json').json()\n",
    "    post = {}\n",
    "    post['Title'] = json_data['title']\n",
    "    post['Creation Time'] = json_data['created_at']\n",
    "    post['View Count'] = json_data['views']\n",
    "    post['Reply Count'] = json_data['reply_count']\n",
    "    post['Like Count'] = json_data['like_count']\n",
    "    post['Link'] = post_link\n",
    "    post['Tags'] = json_data['tags']\n",
    "    post['Question'] = json_data['post_stream']['posts'][0]['cooked']\n",
    "    accpeted_answer = np.nan\n",
    "    for reply in json_data['post_stream']['posts'][1:]:\n",
    "        if reply['accepted_answer']:\n",
    "            accpeted_answer = reply['cooked']\n",
    "            break\n",
    "    post['Accepted Answer'] = accpeted_answer\n",
    "    post = pd.DataFrame([post])\n",
    "    posts = pd.concat([posts, post], ignore_index=True)\n",
    "posts.to_json('OpenAI_official_website.json', orient='records', indent=4)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n",
    "\n",
    "space_info_list = []\n",
    "for space in HfApi().list_spaces():\n",
    "    if space.private:\n",
    "        continue\n",
    "    space_info = {\n",
    "        'id': space.id,\n",
    "        '#like': space.likes,\n",
    "        'creation date': space.created_at,\n",
    "    }\n",
    "    space_info_list.append(space_info)\n",
    "pd.DataFrame(space_info_list).to_json('HuggingFaceSpaces.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import pandas as pd\n",
    "\n",
    "api = HfApi()\n",
    "df = pd.read_json('HuggingFaceSpaces.json')\n",
    "\n",
    "df_filter = pd.DataFrame()\n",
    "for index, row in df.iterrows():\n",
    "    if index % 100:\n",
    "        df_filter.to_json('HuggingFaceSpaces_filtered.json', orient='records', indent=4)\n",
    "    space_id = row['id']\n",
    "    if not row['#like']:\n",
    "        continue\n",
    "    try:\n",
    "        if not api.get_space_runtime(space_id).stage in ['RUNNING', 'SLEEPING']:\n",
    "            continue\n",
    "        if not len(list(api.get_repo_discussions(repo_id=space_id, repo_type=\"space\"))):\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    df_filter = pd.concat([df_filter, pd.DataFrame([row])], ignore_index=True)\n",
    "    print(index, space_id)\n",
    "\n",
    "df_filter = pd.DataFrame(df_filter)\n",
    "df_filter.to_json('HuggingFaceSpaces_filtered.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import get_repo_discussions, get_discussion_details\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "with open('valid_repos_HF.txt') as f:\n",
    "    repos = f.read().splitlines()\n",
    "    for repo in repos:\n",
    "        repo = repo.split('https://huggingface.co/spaces/')[1]\n",
    "        try:\n",
    "            discussions = get_repo_discussions(repo_id=repo, repo_type=\"space\", discussion_type=\"discussion\")\n",
    "            for discussion in discussions:\n",
    "                info = {\n",
    "                    'Title': discussion.title,\n",
    "                    'Created At': discussion.created_at\n",
    "                }\n",
    "                discussion_details = get_discussion_details(repo_id=repo, repo_type=\"space\", discussion_num=discussion.num)\n",
    "                for index, event in enumerate(discussion_details.events):\n",
    "                    if not index and event.type == 'comment':\n",
    "                        info['Body'] = event.content\n",
    "                    if event.type == 'status-change' and event.new_status == 'closed':\n",
    "                        info['Closed At'] = event.created_at\n",
    "                        break\n",
    "                df = pd.concat([df, pd.DataFrame([info])], ignore_index=True)\n",
    "                df.to_json(f'HuggingFace_discussions.jsonl', orient='records', lines=True)\n",
    "        except:\n",
    "            print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge number of tokens: 204.06081320812734\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "df = pd.read_json('HuggingFace_discussions.jsonl', lines=True)\n",
    "\n",
    "total_tokens = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Title'] + row['Body']\n",
    "    tokens = tokenizer.encode(text, disallowed_special=())\n",
    "    token_count = len(tokens)\n",
    "    total_tokens += token_count\n",
    "\n",
    "print(f'Averge number of tokens: {total_tokens / len(df)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
