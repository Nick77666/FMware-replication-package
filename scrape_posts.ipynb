{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_post_mapping = {\n",
    "    'CharacterAI': ['CharacterAI', 'CharacterAi_NSFW'],\n",
    "    'HuggingChat': ['HuggingChat'],\n",
    "    'OpenAI': ['GPTStore', 'GPTStoreFR', 'ChatGPTStore'],\n",
    "    'Poe': ['Poe_AI', 'PoeAI_NSFW'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import json\n",
    "\n",
    "with open('.reddit.json') as f:\n",
    "    config = json.load(f)\n",
    "    reddit = praw.Reddit(**config)\n",
    "    for forum in reddit_post_mapping:\n",
    "        df = pd.DataFrame()\n",
    "        for subreddit in reddit_post_mapping[forum]:\n",
    "            posts = []\n",
    "            for submission in reddit.subreddit(subreddit).hot(limit=None):\n",
    "                posts.append({\n",
    "                    'Title': submission.title,\n",
    "                    'Question': submission.selftext,\n",
    "                    'subreddit': submission.subreddit.display_name,\n",
    "                    'Link': \"https://www.reddit.com\" + submission.permalink,\n",
    "                    'Creation Time': submission.created,\n",
    "                    'Reply Count': submission.num_comments,\n",
    "                    'Upvote Ratio': submission.upvote_ratio\n",
    "                })\n",
    "            df = pd.concat([df, pd.DataFrame(posts)], ignore_index=True)\n",
    "        df.to_json(f'{forum}_reddit.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "tag_store_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "url = 'https://community.openai.com/tags'\n",
    "driver.get(url)\n",
    "\n",
    "for tag in driver.find_elements(By.XPATH, '//div[@class=\"tag-box\"]/a'):\n",
    "    tag_name = tag.get_attribute('data-tag-name')\n",
    "    if 'store' in tag_name.lower():\n",
    "        tag_store_links.append(tag.get_attribute('href'))\n",
    "        \n",
    "post_store_links = set()\n",
    "\n",
    "for tag_link in tag_store_links:\n",
    "    driver.get(tag_link)\n",
    "    for post in driver.find_elements(By.XPATH, '//tbody[@class=\"topic-list-body\"]/tr'):\n",
    "        post_link = post.find_element(By.XPATH, './/a[@role=\"heading\"]').get_attribute('href')\n",
    "        post_store_links.add(post_link)\n",
    "        \n",
    "posts = pd.DataFrame()\n",
    "for post_link in post_store_links:\n",
    "    json_data = requests.get(post_link + '.json').json()\n",
    "    post = {}\n",
    "    post['Title'] = json_data['title']\n",
    "    post['Creation Time'] = json_data['created_at']\n",
    "    post['View Count'] = json_data['views']\n",
    "    post['Reply Count'] = json_data['reply_count']\n",
    "    post['Like Count'] = json_data['like_count']\n",
    "    post['Link'] = post_link\n",
    "    post['Tags'] = json_data['tags']\n",
    "    post['Question'] = json_data['post_stream']['posts'][0]['cooked']\n",
    "    accpeted_answer = np.nan\n",
    "    for reply in json_data['post_stream']['posts'][1:]:\n",
    "        if reply['accepted_answer']:\n",
    "            accpeted_answer = reply['cooked']\n",
    "            break\n",
    "    post['Accepted Answer'] = accpeted_answer\n",
    "    post = pd.DataFrame([post])\n",
    "    posts = pd.concat([posts, post], ignore_index=True)\n",
    "posts.to_json('OpenAI_official_website.json', orient='records', indent=4)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "index = 3268\n",
    "while True:\n",
    "    url = f'https://huggingface.co/spaces?p={index}&sort=created'\n",
    "    driver.get(url)\n",
    "    space = driver.find_elements(By.XPATH, '//article/a')\n",
    "    if not space:\n",
    "        break\n",
    "    space_urls = [s.get_attribute('href') for s in space]\n",
    "    index += 1\n",
    "    print(index)\n",
    "    time.sleep(10)\n",
    "\n",
    "    if index % 10 == 0:\n",
    "        with open('huggingface_spaces.text', 'a') as f:\n",
    "            for url in space_urls:\n",
    "                f.write(url + '\\n')\n",
    "\n",
    "with open('huggingface_spaces.text', 'a') as f:\n",
    "    for url in space_urls:\n",
    "        f.write(url + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
