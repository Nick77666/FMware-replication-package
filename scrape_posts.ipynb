{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmy/Documents/GitHub/GPT-Store-REsearch/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import json\n",
    "\n",
    "with open('.reddit.json') as f:\n",
    "    config = json.load(f)\n",
    "    reddit = praw.Reddit(**config)\n",
    "    subreddit = reddit.subreddit('GPTStore')\n",
    "    posts = pd.DataFrame()\n",
    "    for submission in subreddit.new(limit = None):\n",
    "        post = {\n",
    "            'Title': submission.title,\n",
    "            'Question': submission.selftext,\n",
    "            'subreddit': submission.subreddit.display_name,\n",
    "            'Link': \"https://www.reddit.com\" + submission.permalink,\n",
    "            'Creation Time': submission.created,\n",
    "            'Reply Count': submission.num_comments,\n",
    "            'Upvote Ratio': submission.upvote_ratio\n",
    "        }\n",
    "        post = pd.DataFrame([post])\n",
    "        posts = pd.concat([posts, post], ignore_index=True)\n",
    "    posts.to_json('reddit_store_posts.json', orient='records', indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "tag_store_links = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "url = 'https://community.openai.com/tags'\n",
    "driver.get(url)\n",
    "\n",
    "for tag in driver.find_elements(By.XPATH, '//div[@class=\"tag-box\"]/a'):\n",
    "    tag_name = tag.get_attribute('data-tag-name')\n",
    "    if 'store' in tag_name.lower():\n",
    "        tag_store_links.append(tag.get_attribute('href'))\n",
    "        \n",
    "post_store_links = set()\n",
    "\n",
    "for tag_link in tag_store_links:\n",
    "    driver.get(tag_link)\n",
    "    for post in driver.find_elements(By.XPATH, '//tbody[@class=\"topic-list-body\"]/tr'):\n",
    "        post_link = post.find_element(By.XPATH, './/a[@role=\"heading\"]').get_attribute('href')\n",
    "        post_store_links.add(post_link)\n",
    "        \n",
    "posts = pd.DataFrame()\n",
    "for post_link in post_store_links:\n",
    "    json_data = requests.get(post_link + '.json').json()\n",
    "    post = {}\n",
    "    post['Title'] = json_data['title']\n",
    "    post['Creation Time'] = json_data['created_at']\n",
    "    post['View Count'] = json_data['views']\n",
    "    post['Reply Count'] = json_data['reply_count']\n",
    "    post['Like Count'] = json_data['like_count']\n",
    "    post['Link'] = post_link\n",
    "    post['Tags'] = json_data['tags']\n",
    "    post['Question'] = json_data['post_stream']['posts'][0]['cooked']\n",
    "    accpeted_answer = np.nan\n",
    "    for reply in json_data['post_stream']['posts'][1:]:\n",
    "        if reply['accepted_answer']:\n",
    "            accpeted_answer = reply['cooked']\n",
    "            break\n",
    "    post['Accepted Answer'] = accpeted_answer\n",
    "    post = pd.DataFrame([post])\n",
    "    posts = pd.concat([posts, post], ignore_index=True)\n",
    "posts.to_json('openai_store_posts.json', orient='records', indent=4)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import webbrowser\n",
    "\n",
    "def input_challenge_type(link):\n",
    "    print(link)\n",
    "    \n",
    "    # Adjusted mapping to handle empty string as 'na'\n",
    "    choice_mapping = {\n",
    "        \"K\": 'knowledge',\n",
    "        \"\": 'na',  # Using empty string to represent 'N'/'na' choice\n",
    "        \"P\": 'problem',\n",
    "    }\n",
    "    valid_options = [\"P\", \"K\", \"\"]  # Empty string as a valid option\n",
    "    \n",
    "    webbrowser.open(link)\n",
    "    choice = input(\"Choose an option - 'P', 'K', or press Enter for 'N': \").upper()\n",
    "\n",
    "    # Adjusting the condition to check for an empty string as well\n",
    "    while choice not in valid_options:\n",
    "        print(\"Invalid choice. Please choose 'P', 'K', or press Enter for 'N' only.\")\n",
    "        choice = input(\"Choose an option - 'P', 'K', or press Enter for 'N': \").upper()\n",
    "\n",
    "    return choice_mapping[choice]\n",
    "\n",
    "post_files = ['reddit_plugin_posts.json']\n",
    "for post_file in post_files:\n",
    "    df = pd.read_json(post_file)\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'Challenge Type'] = input_challenge_type(row['Link'])\n",
    "        if index % 5 == 0:\n",
    "            df.to_json(post_file, orient='records', indent=4)\n",
    "    df.to_json(post_file, orient='records', indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
